{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils.pre_processor import processor_use_lemma_plus as processor\n",
    "from utils.const.stopwords import STOPWORDS\n",
    "from gensim.models import LdaModel\n",
    "from gensim import corpora\n",
    "import gensim\n",
    "from utils.const import paths\n",
    "from nltk.tokenize import word_tokenize\n",
    "from utils.const.stopwords import html_stop_words\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import sys\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_documents(documents: List[str]) -> List[List[str]]:\n",
    "    # 分割每个文档中的单词，并将结果存储在列表中\n",
    "    return [document.split() for document in documents]\n",
    "\n",
    "\n",
    "def read_documents_from_folder(folder_path: str, stop_words=None) -> List[str]:\n",
    "    print(\"Reading documents\")\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path):\n",
    "            print(\"Reading year: {}\".format(file_path))\n",
    "            with open(file_path, 'r') as file:\n",
    "                lines = file.readlines()\n",
    "                # cleaned_text = processor(lines, STOPWORDS)\n",
    "                cleaned_texts = []\n",
    "                for line in lines:\n",
    "                    words = word_tokenize(line)\n",
    "                    cleaned_line = ' '.join(\n",
    "                        [word for word in words if word.lower() not in stop_words])\n",
    "                    cleaned_texts.append(cleaned_line)\n",
    "                documents.extend(cleaned_texts)\n",
    "    return documents\n",
    "\n",
    "\n",
    "def find_lda(texts: List[str], n_topics: int = 20, save: bool = True, save_path: str = None) -> None:\n",
    "    print(\"Finding LDA\")\n",
    "    texts = split_documents(texts)\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "    ldamodel = LdaModel(corpus, num_topics=n_topics,\n",
    "                        id2word=dictionary, passes=10)\n",
    "    \n",
    "    if save:\n",
    "        ldamodel.save(save_path)\n",
    "    topics = ldamodel.print_topics(num_words=10)\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "    \n",
    "    return ldamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_folder_path = paths.all_data\n",
    "year_folder = os.listdir(total_folder_path)\n",
    "total_documents = []\n",
    "for year in year_folder:\n",
    "    folder_path = os.path.join(total_folder_path, year)\n",
    "    documents = read_documents_from_folder(folder_path, html_stop_words)\n",
    "    total_documents.extend(documents)\n",
    "lda_model = find_lda(total_documents, 20, save=True,\n",
    "            save_path=paths.lda_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.057*\"value\" + 0.030*\"carry\" + 0.026*\"impairment\" + 0.024*\"asset\" + 0.022*\"unit\" + 0.020*\"charge\" + 0.019*\"service\" + 0.019*\"complete\" + 0.019*\"report\" + 0.016*\"goodwill\"')\n",
      "(1, '0.047*\"service\" + 0.020*\"customer\" + 0.014*\"inventory\" + 0.014*\"delivery\" + 0.014*\"condition\" + 0.013*\"support\" + 0.009*\"operation\" + 0.007*\"reduction\" + 0.007*\"future\" + 0.007*\"repair\"')\n",
      "(2, '0.043*\"may\" + 0.027*\"market\" + 0.025*\"capital\" + 0.023*\"credit\" + 0.021*\"significant\" + 0.015*\"company\" + 0.015*\"risk\" + 0.012*\"control\" + 0.012*\"include\" + 0.012*\"defense\"')\n",
      "(3, '0.033*\"customer\" + 0.026*\"nbsp\" + 0.023*\"lease\" + 0.019*\"term\" + 0.018*\"certain\" + 0.017*\"include\" + 0.017*\"defense\" + 0.016*\"future\" + 0.016*\"service\" + 0.015*\"product\"')\n",
      "(4, '0.033*\"business\" + 0.028*\"aircraft\" + 0.027*\"service\" + 0.023*\"product\" + 0.023*\"also\" + 0.016*\"segment\" + 0.015*\"sale\" + 0.015*\"nbsp\" + 0.015*\"fiscal\" + 0.014*\"cost\"')\n",
      "(5, '0.029*\"service\" + 0.025*\"also\" + 0.023*\"system\" + 0.020*\"provide\" + 0.017*\"design\" + 0.015*\"nbsp\" + 0.013*\"manufacture\" + 0.013*\"include\" + 0.013*\"support\" + 0.013*\"use\"')\n",
      "(6, '0.023*\"part\" + 0.019*\"result\" + 0.018*\"program\" + 0.018*\"inventory\" + 0.018*\"may\" + 0.015*\"award\" + 0.015*\"cost\" + 0.015*\"u\" + 0.015*\"repair\" + 0.013*\"could\"')\n",
      "(7, '0.042*\"aar\" + 0.029*\"nbsp\" + 0.027*\"airlift\" + 0.023*\"condition\" + 0.023*\"inc\" + 0.019*\"group\" + 0.019*\"industry\" + 0.015*\"district\" + 0.015*\"dyncorp\" + 0.012*\"impact\"')\n",
      "(8, '0.033*\"service\" + 0.024*\"segment\" + 0.021*\"sale\" + 0.016*\"within\" + 0.016*\"line\" + 0.015*\"new\" + 0.014*\"nbsp\" + 0.014*\"result\" + 0.013*\"fiscal\" + 0.012*\"lease\"')\n",
      "(9, '0.029*\"demand\" + 0.025*\"business\" + 0.021*\"result\" + 0.019*\"level\" + 0.019*\"u\" + 0.019*\"government\" + 0.017*\"product\" + 0.015*\"utilize\" + 0.015*\"include\" + 0.015*\"future\"')\n",
      "(10, '0.048*\"operation\" + 0.048*\"financial\" + 0.046*\"adversely\" + 0.046*\"affect\" + 0.040*\"result\" + 0.038*\"could\" + 0.031*\"condition\" + 0.024*\"may\" + 0.019*\"u\" + 0.015*\"cost\"')\n",
      "(11, '0.023*\"fiscal\" + 0.019*\"tax\" + 0.016*\"supply\" + 0.016*\"chain\" + 0.016*\"activity\" + 0.016*\"nbsp\" + 0.015*\"low\" + 0.014*\"result\" + 0.013*\"increase\" + 0.013*\"aviation\"')\n",
      "(12, '0.226*\"nbsp\" + 0.070*\"million\" + 0.045*\"sale\" + 0.036*\"increase\" + 0.033*\"prior\" + 0.033*\"year\" + 0.030*\"fiscal\" + 0.028*\"primarily\" + 0.022*\"decrease\" + 0.018*\"service\"')\n",
      "(13, '0.024*\"report\" + 0.024*\"unit\" + 0.022*\"include\" + 0.021*\"goodwill\" + 0.020*\"aviation\" + 0.018*\"may\" + 0.016*\"four\" + 0.014*\"also\" + 0.012*\"contract\" + 0.012*\"repair\"')\n",
      "(14, '0.029*\"fiscal\" + 0.017*\"transaction\" + 0.016*\"quarter\" + 0.014*\"result\" + 0.013*\"recognition\" + 0.013*\"facility\" + 0.013*\"earnings\" + 0.013*\"loss\" + 0.013*\"saleleaseback\" + 0.013*\"fourth\"')\n",
      "(15, '0.015*\"commercial\" + 0.015*\"service\" + 0.012*\"aviation\" + 0.012*\"may\" + 0.011*\"certain\" + 0.011*\"state\" + 0.011*\"component\" + 0.011*\"repair\" + 0.011*\"increase\" + 0.011*\"development\"')\n",
      "(16, '0.038*\"aircraft\" + 0.030*\"airline\" + 0.029*\"maintenance\" + 0.026*\"operate\" + 0.024*\"number\" + 0.018*\"value\" + 0.018*\"asset\" + 0.017*\"reduce\" + 0.017*\"may\" + 0.016*\"activity\"')\n",
      "(17, '0.028*\"cash\" + 0.015*\"remain\" + 0.015*\"could\" + 0.014*\"service\" + 0.014*\"flow\" + 0.014*\"continue\" + 0.012*\"result\" + 0.012*\"aircraft\" + 0.010*\"defense\" + 0.010*\"government\"')\n",
      "(18, '0.022*\"also\" + 0.021*\"nbsp\" + 0.021*\"company\" + 0.021*\"serve\" + 0.020*\"mr\" + 0.020*\"since\" + 0.014*\"march\" + 0.014*\"debt\" + 0.014*\"major\" + 0.014*\"could\"')\n",
      "(19, '0.155*\"nbsp\" + 0.018*\"service\" + 0.013*\"business\" + 0.012*\"aar\" + 0.012*\"court\" + 0.012*\"telair\" + 0.011*\"may\" + 0.011*\"product\" + 0.009*\"include\" + 0.009*\"aircraft\"')\n"
     ]
    }
   ],
   "source": [
    "# Test code\n",
    "# file_path = \"/Users/weichentao/Documents/USC/2023fall/540/project/select_valuable/valuable/cleaned/2017/1750_000104746917004528_a2232622z10-k.htm.txt\"\n",
    "# with open(file_path, 'r') as file:\n",
    "#     lines = file.readlines()\n",
    "#     cleaned_text = processor(lines, STOPWORDS)\n",
    "#     lda_model = find_lda(cleaned_text, 20, save=True,\n",
    "#                 save_path=paths.lda_model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
